{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C1/W3/ungraded_labs/C1_W3_Lab_2_exploring_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJTHvE8Qe5nM"
   },
   "source": [
    "# Ungraded Lab: Exploring Convolutions\n",
    "\n",
    "In this lab, you will explore how convolutions work by creating a basic convolution on a 2D grayscale image. First, you will load the image by taking the [ascent](https://docs.scipy.org/doc/scipy/reference/generated/scipy.datasets.ascent.html) image from [SciPy](https://scipy.org/). It's a nice, built-in picture with lots of angles and lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************\n",
    "**********************************************************\n",
    "**********************************************************\n",
    "**********************************************************\n",
    "\n",
    "THis notebook wasnt running easily ewnough so i did it in the colab env (see \"Completed on colab\" version (ipynb file in this same filepath: C1\\W3\\ungraded_labs\\Completed on colab--Copy_of_C1_W3_Lab_2_exploring_convolutions.ipynb))\n",
    "\n",
    "**********************************************************\n",
    "**********************************************************\n",
    "**********************************************************\n",
    "**********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1639058947063,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "DZ5OXYiolCUi"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ascent\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# load the ascent image\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ascent_image \u001b[38;5;241m=\u001b[39m ascent()\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\scipy\\datasets\\__init__.py:81\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mDatasets (:mod:`scipy.datasets`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fetchers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m face, ascent, electrocardiogram\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_download_all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_all\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_cache\n\u001b[0;32m     84\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melectrocardiogram\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     85\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownload_all\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclear_cache\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\scipy\\datasets\\_download_all.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpooch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     pooch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\pooch\\__init__.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2018 The Pooch Developers.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Import functions/classes to make the API\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pooch, create, retrieve\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m os_cache, check_version, get_logger\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_hash, make_registry\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\pooch\\core.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshlex\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hash_matches, file_hash\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\requests\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m charset_normalizer_version\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     charset_normalizer_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32mc:\\Users\\me\\.conda\\envs\\tf1\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from scipy.datasets import ascent\n",
    "# load the ascent image\n",
    "ascent_image = ascent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRIzxjWWfJjk"
   },
   "source": [
    "You can use the pyplot library to draw the image so you'll know what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1639059000048,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "R4p0cfWcfIvi",
    "outputId": "4565e085-4fb0-4129-8e83-ee4dc6646250"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the image\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(ascent_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1mhZ_ZTfPWH"
   },
   "source": [
    "The image is stored as a numpy array so you can create the transformed image by first copying that array. You can also get the dimensions of the image so you can loop over it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1639059122348,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "o5pxGq1SmJMD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy image to a numpy array\n",
    "image_transformed = np.copy(ascent_image)\n",
    "\n",
    "# Get the dimensions of the image\n",
    "size_x = image_transformed.shape[0]\n",
    "size_y = image_transformed.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7PwNkiXfddd"
   },
   "source": [
    "Now you can create a filter as a 3x3 array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1639059236890,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "sN3imZannN5J"
   },
   "outputs": [],
   "source": [
    "# Experiment with different values and see the effect\n",
    "filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "\n",
    "# A couple more filters to try for fun!\n",
    "# filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "# filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "\n",
    "# If all the digits in the filter don't add up to 0 or 1, you \n",
    "# should probably do a weight to get it to do so\n",
    "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
    "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
    "weight  = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQmm_iBufmCz"
   },
   "source": [
    "Now you can create a convolution. You will iterate over the image, leaving a 1 pixel margin, and multiplying each of the neighbors of the current pixel by the value defined in the filter (i.e. the current pixel's neighbor above it and to the left will be multiplied by the top left item in the filter, etc.) \n",
    "\n",
    "You'll then multiply the result by the weight, and then ensure the result is in the range 0-255.\n",
    "\n",
    "Finally you'll load the new value into the transformed image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3511,
     "status": "ok",
     "timestamp": 1639059241813,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "299uU2jAr90h"
   },
   "outputs": [],
   "source": [
    "# Iterate over the image\n",
    "for x in range(1,size_x-1):\n",
    "  for y in range(1,size_y-1):\n",
    "      convolution = 0.0\n",
    "      convolution = convolution + (ascent_image[x-1, y-1] * filter[0][0])\n",
    "      convolution = convolution + (ascent_image[x-1, y] * filter[0][1])  \n",
    "      convolution = convolution + (ascent_image[x-1, y+1] * filter[0][2])     \n",
    "      convolution = convolution + (ascent_image[x, y-1] * filter[1][0])    \n",
    "      convolution = convolution + (ascent_image[x, y] * filter[1][1])    \n",
    "      convolution = convolution + (ascent_image[x, y+1] * filter[1][2])    \n",
    "      convolution = convolution + (ascent_image[x+1, y-1] * filter[2][0])    \n",
    "      convolution = convolution + (ascent_image[x+1, y] * filter[2][1])    \n",
    "      convolution = convolution + (ascent_image[x+1, y+1] * filter[2][2])    \n",
    "      \n",
    "      # Multiply by weight\n",
    "      convolution = convolution * weight   \n",
    "      \n",
    "      # Check the boundaries of the pixel values\n",
    "      if(convolution<0):\n",
    "        convolution=0\n",
    "      if(convolution>255):\n",
    "        convolution=255\n",
    "\n",
    "      # Load into the transformed image\n",
    "      image_transformed[x, y] = convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XA--vgvgDEQ"
   },
   "source": [
    "After the loop, you can now plot the image to see the effect of the convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1639059523867,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "7oPhUPNhuGWC",
    "outputId": "2aee35d3-e378-441c-e497-1c215722c34c"
   },
   "outputs": [],
   "source": [
    "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(image_transformed)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF0FPplsgHNh"
   },
   "source": [
    "## Effect of Max Pooling\n",
    "\n",
    "The next cell will show a (2, 2) pooling. The idea here is to iterate over the image, and look at the pixel and it's immediate neighbors to the right, beneath, and right-beneath. It will take the largest of them and load it into the new image. Thus, the new image will be 1/4 the size of the old -- with the dimensions on X and Y being halved by this process. You'll see that the features get maintained despite this compression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 1881,
     "status": "ok",
     "timestamp": 1639059312953,
     "user": {
      "displayName": "Chris Favila",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17311369472417335306"
     },
     "user_tz": -480
    },
    "id": "kDHjf-ehaBqm",
    "outputId": "3d0837c6-11d6-44e0-a470-8c7a2f139d88"
   },
   "outputs": [],
   "source": [
    "# Assign dimensions half the size of the original image\n",
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "\n",
    "# Create blank image with reduced dimensions\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "\n",
    "# Iterate over the image\n",
    "for x in range(0, size_x, 2):\n",
    "  for y in range(0, size_y, 2):\n",
    "    \n",
    "    # Store all the pixel values in the (2,2) pool\n",
    "    pixels = []\n",
    "    pixels.append(image_transformed[x, y])\n",
    "    pixels.append(image_transformed[x+1, y])\n",
    "    pixels.append(image_transformed[x, y+1])\n",
    "    pixels.append(image_transformed[x+1, y+1])\n",
    "\n",
    "    # Get only the largest value and assign to the reduced image\n",
    "    newImage[int(x/2),int(y/2)] = max(pixels)\n",
    "\n",
    "# Plot the image. Note the size of the axes -- it is now 256 pixels instead of 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "plt.show()      "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W3_Lab_2_exploring_convolutions.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/12_sep_2021_fixes/C1/W3/ungraded_labs/C1_W3_Lab_2_exploring_convolutions.ipynb",
     "timestamp": 1639058610295
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
